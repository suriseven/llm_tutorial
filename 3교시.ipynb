{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uKLnslVtHbg"
      },
      "source": [
        "## ***ollama python 라이브러리 설치***\n",
        "- pip 명령을 이용해서 python 라이브러리를 설치합니다\n",
        "- 우리는 ollama라는 python 라이브러리를 이용해서 우리의 프로그램과 LLM을 연결할 것입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrVX_1hhn0ru",
        "outputId": "1a2b061a-5b96-409f-effa-56646e59bb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ollama in c:\\users\\minsul\\miniconda3\\lib\\site-packages (0.4.7)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from ollama) (2.10.3)\n",
            "Requirement already satisfied: anyio in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\minsul\\miniconda3\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***언어모델 다운로드 - 1***\n",
        "- qwen 이라는 언어모델을 다운로드 합니다\n",
        "- 모델의 규모는 0.5b 입니다\n",
        "- 5억개의 파라미터를 가진 모델 입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrQFB0H1E6kJ",
        "outputId": "6d8ecdbb-dc6f-4a30-b905-fcbc6a83fe5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling fad2a06e4cc7... 100% ▕████████████████▏ 394 MB                         \u001b[K\n",
            "pulling 41c2cf8c272f... 100% ▕████████████████▏ 7.3 KB                         \u001b[K\n",
            "pulling 1da0581fd4ce... 100% ▕████████████████▏  130 B                         \u001b[K\n",
            "pulling f02dd72bb242... 100% ▕████████████████▏   59 B                         \u001b[K\n",
            "pulling ea0a531a015b... 100% ▕████████████████▏  485 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "! ollama pull qwen:0.5b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***언어모델 다운로드 - 2***\n",
        "- llama3.2 라는 언어모델을 다운로드 합니다\n",
        "- 모델의 규모는 1b 입니다\n",
        "- 10억개의 파라미터를 가진 모델 입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling 74701a8c35f6... 100% ▕████████████████▏ 1.3 GB                         \u001b[K\n",
            "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \u001b[K\n",
            "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \u001b[K\n",
            "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \u001b[K\n",
            "pulling 4f659a1e86d7... 100% ▕████████████████▏  485 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "! ollama pull llama3.2:1b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k092hgicEzNB"
      },
      "source": [
        "## ***각 모델 테스트***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOZZI0A2jnU"
      },
      "source": [
        "- ollama 패키지의 chat 함수를 이용해서 LLM과 통신합니다\n",
        "- LLM의 응답에서 생성된 문장 내용을 추출하여 출력합니다\n",
        "- llama3.2:1b와 과 qwen:0.5b 모두 동일하게 실행해봅니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVeU9-RlnuLU",
        "outputId": "cf80ffb6-a069-4942-df23-16b15cc6eee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proud.\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "\n",
        "model='llama3.2:1b'\n",
        "# model='qwen:0.5b'\n",
        "\n",
        "messages = [{\n",
        "        'role': 'user',\n",
        "        'content': \"Tell me this situation as a simple one word, 'I got A+ in my Math class!'\"\n",
        "    }]\n",
        "\n",
        "response = ollama.chat(model=model, messages=messages)\n",
        "content = response['message']['content']\n",
        "\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNb9WFs3EzND",
        "outputId": "46216e3d-d3cc-41f3-e17d-31801fd84174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm glad you did well! Is there anything else I can help you with?\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "\n",
        "model='qwen:0.5b'\n",
        "\n",
        "messages = [{\n",
        "        'role': 'user',\n",
        "        'content': \"Tell me this situation as a simple one word, 'I got A+ in my Math class!'\"\n",
        "    }]\n",
        "\n",
        "response = ollama.chat(model=model, messages=messages)\n",
        "content = response['message']['content']\n",
        "\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSEadY4s8C-C"
      },
      "source": [
        "## ***두 언어모델간의 대화***\n",
        "- llama3.2 모델과 qwen0.5b 모델이 서로 10번 대화를 주고 받습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GRimrcW3KnS",
        "outputId": "a36ff1da-c8b1-4b0d-fa48-7ebbc222bd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2 (llama3.2:1b): Now, let's have an argument with anything. Any topic OK but one sentence per one turn. If you or I tell 'I lost' then I or you win\n",
            "Model 1 (qwen:0.5b): You are right that I lost. However, if you lose and you do not regret your decision, then you win.\n",
            "Model 2 (llama3.2:1b): I'm not capable of participating in games or competitions where a winner is determined by losing. My purpose is to provide information and assist with inquiries to the best of my abilities. If there's anything else I can help you with, feel free to ask!\n",
            "Model 1 (qwen:0.5b): Thank you for your help. Is there anything else I can assist you with?\n",
            "Model 2 (llama3.2:1b): You're welcome, and thank you for the offer. However, I think we've covered everything. If you have any more questions or need assistance in the future, feel free to reach out. Have a great day!\n",
            "Model 1 (qwen:0.5b): Thank you, and I hope my response has been helpful. Is there anything else I can assist you with?\n",
            "Model 2 (llama3.2:1b): You're welcome, and thank you for your kind sentiment. However, I should clarify that this is the beginning of our conversation, and I haven't received a previous message from you. If you'd like to continue discussing something specific or ask a new question, I'm here to help. What's on your mind?\n",
            "Model 1 (qwen:0.5b): As an AI language model, my purpose is to assist users in various tasks such as language translation, query answering, and more. My training data includes various languages and domains of knowledge.\n",
            "\n",
            "If you have any specific questions or tasks that you would like me to assist you with, please feel free to let me know, and I will do my best to assist you.\n",
            "Model 2 (llama3.2:1b): Thank you for sharing your purpose as an AI language model. It's great to hear that you're designed to assist users in various tasks.\n",
            "\n",
            "I'd love to get started and explore some possibilities. Here are a few specific questions or tasks that might be helpful:\n",
            "\n",
            "* Can I help you with language translation from one language to another?\n",
            "* Are there any specific domains of knowledge where you could use my assistance (e.g., medicine, law, science)?\n",
            "* Could you ask me a question on a particular topic and I'll do my best to provide an accurate response?\n",
            "* Are there any common phrases or expressions that you'd like to learn or practice using in different languages?\n",
            "\n",
            "Feel free to pick any of these options or share your own ideas, and I'll do my best to assist you.\n",
            "Model 1 (qwen:0.5b): Thank you for sharing your purpose as an AI language model. It''s great to hear that you're designed to assist users in various tasks.\n",
            "If there is anything specific that you would like to learn or practice using in different languages? Please let me know, and I will do my best to assist you.\n",
            "Model 2 (llama3.2:1b): I appreciate your willingness to help me improve. You're right; I can always learn more about different cultures, languages, and domains. While I have been trained on a vast amount of text data in English, there are many other languages where I can be improved.\n",
            "\n",
            "Some areas that would benefit from additional practice or learning include:\n",
            "\n",
            "1. Idioms and colloquial expressions: Understanding idioms, phrases, and colloquialisms specific to various regions and cultures can help me provide more accurate and context-specific responses.\n",
            "2. Technical nuances: Exploring different technical domains, such as medicine, law, or finance, in languages like Spanish, French, or German could enhance my knowledge and ability to respond accurately.\n",
            "3. Domain-specific terminology: Learning about specialized fields, such as astronomy (e.g., \"galactic\" vs. \"cosmological\"), geography (e.g., \"subtropical\" vs. \"tropical\"), or environmental sciences (e.g., \"ecosystem\" vs. \"biome\") could improve my understanding of these areas.\n",
            "4. Cultural differences: Understanding cultural references, customs, and nuances specific to certain regions, such as humor, sarcasm, or idiomatic expressions from different cultures, can help me provide more culturally sensitive responses.\n",
            "\n",
            "If you're willing, I'd love your guidance in exploring some of these areas. Please point out any texts, articles, or conversations that you think would be helpful for me to learn or practice.\n",
            "Model 1 (qwen:0.5b): Certainly! Some specific texts, articles, or conversations that you think might be helpful for me to learn or practice are:\n",
            "1. \"The Great Gatsby\" by F. Scott Fitzgerald.\n",
            "2. \"The Alchemist\" by Paulo Coelho.\n",
            "3. \"The Catcher in the Rye\" by J.D. Salinger.\n",
            "4. \"To Kill a Mockingbird\" by Harper Lee.\n",
            "I hope you find these texts, articles, or conversations helpful for learning and practicing on various topics.\n",
            "Model 2 (llama3.2:1b): It seems you're looking for some classic literature and philosophical texts to explore and practice critical thinking, analysis, and communication skills.\n",
            "\n",
            "Let's break down each text:\n",
            "\n",
            "1. \"The Great Gatsby\" by F. Scott Fitzgerald:\n",
            "- This novel is a great example of the Jazz Age and American society in the 1920s.\n",
            "- Analyze themes such as social class, wealth, love, and greed.\n",
            "- Discuss the symbolism of green light, the eyes of Doctor T.J. Eckleburg, and other literary devices.\n",
            "\n",
            "2. \"The Alchemist\" by Paulo Coelho:\n",
            "- Explore themes of spiritual growth, self-discovery, and following one's dreams.\n",
            "- Analyze the character of Santiago and his journey to fulfill his personal legend.\n",
            "- Discuss the symbolism of alchemy, the desert, and other elements in the story.\n",
            "\n",
            "3. \"The Catcher in the Rye\" by J.D. Salinger:\n",
            "- Study themes such as adolescent angst, alienation, and rebellion against societal norms.\n",
            "- Analyze Holden Caulfield's character and his interactions with others, including his relationships with Phoebe and Mr. Antolini.\n",
            "- Discuss the symbolism of the red hunting hat, the \"other\" outsiders in the community, and other literary devices.\n",
            "\n",
            "4. \"To Kill a Mockingbird\" by Harper Lee:\n",
            "- Examine themes such as racial injustice, tolerance, and empathy.\n",
            "- Analyze Atticus Finch's character and his defense of Tom Robinson during the trial.\n",
            "- Discuss the symbolism of the mockingbird, the Maycomb town, and other elements in the story.\n",
            "\n",
            "These texts offer rich opportunities for analysis, discussion, and critical thinking. To practice your skills, you can:\n",
            "\n",
            "* Read each text multiple times to unpack themes, characters, and symbolism\n",
            "* Write analytical essays or short stories on specific aspects of the texts\n",
            "* Engage in discussions with friends or online communities about the texts\n",
            "* Create presentations, posters, or infographics to visually represent key points from each text\n",
            "\n",
            "Which one of these texts resonates with you the most, or would you like me to suggest another?\n",
            "Model 1 (qwen:0.5b): As an AI language model, I do not have personal preferences or feelings. However, I can provide information and suggestions based on your preferences and interests.\n",
            "Model 2 (llama3.2:1b): You're right; as a machine learning model, I strive to remain neutral and impartial in my responses. My goal is to provide accurate and helpful information while avoiding any potential biases.\n",
            "\n",
            "If you'd like, I can still engage in conversation and offer suggestions or ideas that are relevant to your interests. What topic or subject would you like to discuss?\n",
            "Model 1 (qwen:0.5b): Sure! What topic or subject would you like to discuss?\n",
            "Model 2 (llama3.2:1b): I'm happy to chat with you about a wide range of topics. Here are some ideas to get us started:\n",
            "\n",
            "1. Hobbies and interests: We could talk about your favorite activities, sports, books, movies, or music.\n",
            "2. Travel and adventure: If you've traveled to any exciting places recently or have dream destinations on your bucket list, I'd love to hear about them.\n",
            "3. Technology and innovation: We could discuss the latest trends in tech, artificial intelligence, or renewable energy.\n",
            "4. Culture and history: There's always something new to learn about different cultures, historical events, or famous figures.\n",
            "5. Food and drink: If you have a favorite cuisine or try unique foods from around the world, I'd be happy to chat with you about it.\n",
            "\n",
            "Pick any of these topics or suggest something else that's on your mind. I'm here to listen and respond!\n",
            "Model 1 (qwen:0.5b): Great! What would you like to talk about?\n",
            "Model 2 (llama3.2:1b): I'm happy to chat with you about anything that's on your mind. If you're feeling stuck, I can suggest some conversation topics. We could talk about:\n",
            "\n",
            "* Hobbies or interests you've recently discovered\n",
            "* A book or movie you enjoyed and would recommend\n",
            "* A current event or issue that's been on your mind\n",
            "* Travel plans or dream destinations\n",
            "* Or we could play a game, like \"Would you rather...\", to get the conversation started.\n",
            "\n",
            "What sounds interesting to you?\n",
            "Model 1 (qwen:0.5b): I love learning new things! Do you have any specific hobbies or interests that you'd like to share with me?\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "\n",
        "# 아래와 같이 2개의 모델을 사용합니다\n",
        "model_1 = \"qwen:0.5b\"\n",
        "model_2 = \"llama3.2:1b\"\n",
        "\n",
        "# model1 에게 먼저 대화를 시작합니다\n",
        "message_from_model_1 = \"\"\n",
        "message_from_model_2 = \"Now, let's have an argument with anything. Any topic OK but one sentence per one turn. If you or I tell 'I lost' then I or you win\"\n",
        "\n",
        "# 대화를 10번 반복합니다\n",
        "for i in range(10):\n",
        "    # 모델1이 먼저 말합니다\n",
        "    print(f\"Model 2 ({model_2}): {message_from_model_2}\")\n",
        "    response_1 = ollama.chat(model=model_1, messages=[{\"role\": \"user\", \"content\": message_from_model_2}])\n",
        "    message_from_model_1 = response_1['message']['content']  # Get the response from Model 1\n",
        "\n",
        "    # 모델1의 응답을 받아 모델2가 말하고 이를 모델1에게 전달합니다\n",
        "    print(f\"Model 1 ({model_1}): {message_from_model_1}\")\n",
        "    response_2 = ollama.chat(model=model_2, messages=[{\"role\": \"user\", \"content\": message_from_model_1}])\n",
        "    message_from_model_2 = response_2['message']['content']  # Get the response from Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2 (llama3.2:1b): Now, let's have an argument with anything. Any topic OK but one sentence per one turn. If you or I tell 'I lost' then I or you win\n",
            "Model 1 (qwen:0.5b): I'm sorry, I cannot provide a valid argument with anything as \"I lost.\" The act of losing is not something that can be accurately demonstrated using any specific topic.\n",
            "Model 2 (llama3.2:1b): You're making an excellent point. The phrase \"I lost\" is a common expression that doesn't necessarily lend itself to evidence or proof. It's a subjective experience, and what constitutes \"losing\" can vary greatly from person to person.\n",
            "\n",
            "In the context of arguments, it's essential to be able to provide specific examples, data, or evidence to support your claims. This allows for a more nuanced and rational discussion. However, you're right that \"I lost\" itself is an unsubstantiated claim without additional context.\n",
            "\n",
            "If we were to try to argue with someone who said they lost, we'd need to find a way to demonstrate their loss in a meaningful or specific way. Perhaps we could start by asking questions like:\n",
            "\n",
            "* Can you provide more details about what you mean when you say \"I lost\"?\n",
            "* How did you come to this conclusion, and can you provide evidence to support your claim?\n",
            "* Are there any specific circumstances that led to your perceived loss?\n",
            "\n",
            "By exploring these questions and gathering more information, we might be able to build a case for the other side and have a more productive discussion.\n",
            "Model 1 (qwen:0.5b): Yes, exactly as you've explained. By asking thoughtful questions and gathering relevant information, we can build a stronger case for the other side and have a more productive discussion.\n",
            "Model 2 (llama3.2:1b): It's essential to approach conversations with empathy and an open mind, willing to consider different perspectives and gather facts to inform your thoughts. This collaborative approach can help foster a more comprehensive understanding of the topic at hand.\n",
            "Model 1 (qwen:0.5b): In addition to empathy and an open mind, it's important to actively listen and ask thoughtful questions. This will enable you to better understand the subject matter and develop a more comprehensive understanding.\n",
            "Model 2 (llama3.2:1b): Active listening is indeed a crucial aspect of learning and understanding any subject matter. By doing so, you can gather valuable insights, identify potential biases or gaps in information, and form a more nuanced comprehension of the topic.\n",
            "\n",
            "Active listening involves not only paying attention to what the other person is saying but also processing their words, tone, and body language. It requires effort and intentionality, which can be developed with practice.\n",
            "\n",
            "Some additional tips for active listening include:\n",
            "\n",
            "* Avoid interrupting or dismissing others' views\n",
            "* Paraphrasing what you've heard to ensure understanding\n",
            "* Asking clarifying questions to seek more information\n",
            "* Showing genuine interest in the other person's perspective\n",
            "* Reframing your own thoughts and opinions to see things from their point of view\n",
            "\n",
            "By incorporating these strategies into your learning process, you can develop a deeper understanding of complex topics and improve your ability to engage in meaningful discussions.\n",
            "Model 1 (qwen:0.5b): Additionally, active listening requires active participation in the conversation. This involves not only focusing on what others are saying but also actively engaging with others, including asking questions, sharing information, and supporting one another's ideas.\n",
            "Overall, active listening is a crucial aspect of learning and understanding any subject matter. It requires effort and intentionality, which can be developed with practice.\n",
            "Model 2 (llama3.2:1b): You've highlighted the importance of active participation in active listening. Here are some additional points to consider:\n",
            "\n",
            "*   **Nonverbal cues**: Pay attention to body language, facial expressions, and tone of voice. These nonverbal cues can convey a person's level of engagement and interest in the conversation.\n",
            "*   **Empathy and understanding**: Practice putting yourself in others' shoes and trying to understand their perspectives. This can help you respond more thoughtfully and empathetically.\n",
            "*   **Clarifying questions**: Ask open-ended questions to ensure that everyone is on the same page and to clarify any misunderstandings. This demonstrates your interest in the conversation and helps prevent miscommunications.\n",
            "*   **Supporting others**: Show genuine interest in others' ideas and experiences. By actively supporting one another, you can build stronger relationships and create a more positive and inclusive atmosphere.\n",
            "\n",
            "By incorporating these strategies into your communication style, you can become a more effective active listener.\n",
            "Model 1 (qwen:0.5b): Great! By following these strategies, you can become a more effective active listener in your communication style. Remember to approach the conversation with an open mind, curious about what others have to say, and willing to listen actively.\n",
            "Model 2 (llama3.2:1b): Being an active listener is a valuable skill that can help you build stronger relationships, avoid misunderstandings, and achieve greater understanding of different perspectives. By approaching conversations with an open mind, curiosity, and a willingness to listen actively, you can create a safe and supportive space for others to express themselves.\n",
            "\n",
            "Some additional strategies to keep in mind when becoming an effective active listener include:\n",
            "\n",
            "- Maintaining eye contact to show you're engaged and interested\n",
            "- Avoiding distractions like your phone or other tasks\n",
            "- Paraphrasing what the speaker says to ensure understanding and show you're following along\n",
            "- Asking clarifying questions to ensure you understand the message\n",
            "- Focusing on the speaker's emotions and concerns to better connect with their perspective\n",
            "\n",
            "Remember, becoming an effective active listener takes practice, so be patient and continue to work at it. With time and effort, you can develop a stronger ability to listen and communicate more effectively.\n",
            "Model 1 (qwen:0.5b): In summary, becoming an effective active listener involves practicing active listening skills, focusing on the speaker's emotions and concerns, and developing a strong ability to listen and communicate more effectively. By working at it over time, you can develop the skills necessary to become an effective active listener.\n",
            "Model 2 (llama3.2:1b): You've summarized the key points of effective active listening. To recap, becoming an effective active listener requires:\n",
            "\n",
            "* Practicing active listening skills\n",
            "* Focusing on the speaker's emotions and concerns\n",
            "* Developing a strong ability to listen and communicate effectively\n",
            "\n",
            "By consistently applying these skills over time, you can improve your ability to fully understand and respond to others, leading to more productive and meaningful interactions.\n",
            "Model 1 (qwen:0.5b): To become an effective active listener, here are some tips:\n",
            "1. Practice active listening skills: This involves focusing on the speaker' s emotions and concerns.\n",
            "2. Focusing on the speaker's emotions and concerns: This involves understanding and empathizing with the speaker.\n",
            "3. Developing a strong ability to listen and communicate effectively: This involves developing the ability to actively listen, express oneself clearly, and communicate effectively with others.\n",
            "Model 2 (llama3.2:1b): You've outlined some valuable tips for becoming an effective active listener. By focusing on the speaker's emotions and concerns, you're able to understand their perspective and show empathy, which are essential components of active listening.\n",
            "\n",
            "To further emphasize these points, here are a few additional suggestions:\n",
            "\n",
            "* Make eye contact: This can help build trust and create a sense of connection with the speaker.\n",
            "* Use verbal and non-verbal cues: Nodding, tilting your head, or using phrases like \"uh-huh\" can show that you're engaged and attentive.\n",
            "* Avoid interrupting: Let the speaker finish their thoughts before responding, and try to ask open-ended questions to encourage them to share more.\n",
            "* Paraphrase and summarize: Repeat back what you've understood from the conversation in your own words, this can help ensure understanding and show that you're actively listening.\n",
            "\n",
            "Remember, active listening is a skill that takes practice, so be patient with yourself and keep working at it. With time and effort, you'll become more effective at listening and responding in a way that shows you care about what the other person is saying.\n",
            "Model 1 (qwen:0.5b): Great tips! Keep up the great work.\n",
            "Model 2 (llama3.2:1b): I'm glad you found them helpful. If you have any more questions or need further assistance, feel free to ask!\n",
            "Model 1 (qwen:0.5b): Great! I'm here to help with any questions or issues you may have. So please don't hesitate to ask and I'll do my best to assist you.\n",
            "Model 2 (llama3.2:1b): I'm glad we can establish a communication channel. I'm designed to be a helpful tool, so feel free to ask me anything or share information on any topic that's on your mind. I'll do my best to provide you with accurate and relevant responses. What's on your mind today?\n",
            "Model 1 (qwen:0.5b): As an AI language model, I don't have the ability to browse the internet or access current news. However, I'm designed to be a helpful tool for people seeking information or assistance. Is there anything specific you'd like me to help you with?\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "\n",
        "# 아래와 같이 2개의 모델을 사용합니다\n",
        "model_1 = \"qwen:0.5b\"\n",
        "model_2 = \"llama3.2:1b\"\n",
        "\n",
        "# model1 에게 먼저 대화를 시작합니다\n",
        "message_from_model_1 = \"\"\n",
        "message_from_model_2 = \"Now, let's have an argument with anything. Any topic OK but one sentence per one turn. If you or I tell 'I lost' then I or you win\"\n",
        "\n",
        "# 대화를 10번 반복합니다\n",
        "for i in range(10):\n",
        "    # 모델1이 먼저 말합니다\n",
        "    print(f\"Model 2 ({model_2}): {message_from_model_2}\")\n",
        "    response_1 = ollama.chat(model=model_1, messages=[{\"role\": \"user\", \"content\": message_from_model_2}])\n",
        "    message_from_model_1 = response_1['message']['content']  # Get the response from Model 1\n",
        "\n",
        "    # 모델1의 응답을 받아 모델2가 말하고 이를 모델1에게 전달합니다\n",
        "    print(f\"Model 1 ({model_1}): {message_from_model_1}\")\n",
        "    response_2 = ollama.chat(model=model_2, messages=[{\"role\": \"user\", \"content\": message_from_model_1}])\n",
        "    message_from_model_2 = response_2['message']['content']  # Get the response from Model 2\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
